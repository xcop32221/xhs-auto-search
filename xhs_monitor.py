#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å°çº¢ä¹¦çˆ¬è™« - é’é¾™é¢æ¿ç‰ˆ
æœç´¢"æˆéƒ½çº¦å¦†"å…³é”®è¯ï¼Œé€šè¿‡QLAPIå‘é€é€šçŸ¥ï¼Œé¿å…é‡å¤é€šçŸ¥
æ¯10åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡

cron: 0 0,6-23 * * *
new Env('å°çº¢ä¹¦æˆéƒ½çº¦å¦†ç›‘æ§');
"""

import os
import sys
import json
import time
import hashlib
import requests
import random
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

try:
    from main import Data_Spider
    from xhs_utils.common_util import init
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# é’é¾™é¢æ¿QLAPI
try:
    from ql import QLAPI
except ImportError:
    # å¦‚æœä¸åœ¨é’é¾™ç¯å¢ƒä¸­ï¼Œä½¿ç”¨printæ¨¡æ‹Ÿ
    class MockQLAPI:
        @staticmethod
        def notify(data):
            print(f"\n=== é€šçŸ¥ ===")
            print(f"æ ‡é¢˜: {data.get('title', 'æ— æ ‡é¢˜')}")
            print(f"å†…å®¹: {data.get('content', 'æ— å†…å®¹')}")
            print("==========\n")

        @staticmethod
        def systemNotify(data):
            print(f"\n=== ç³»ç»Ÿé€šçŸ¥ ===")
            print(f"æ ‡é¢˜: {data.get('title', 'æ— æ ‡é¢˜')}")
            print(f"å†…å®¹: {data.get('content', 'æ— å†…å®¹')}")
            print("===============\n")
    QLAPI = MockQLAPI()

# é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–
# ä¼˜åŒ–å…³é”®è¯ï¼šæ›´åå‘ç”¨æˆ·éœ€æ±‚çš„è¡¨è¾¾æ–¹å¼
SEARCH_KEYWORDS = os.getenv('XHS_KEYWORDS', 'çº¦å¦†,æˆéƒ½çº¦å¦†,æ‰¾å¦†å¨˜,æ‰¾ä¸ªåŒ–å¦†å¸ˆæ‹å†™çœŸ,ä¸Šé—¨åŒ–å¦†,ä¸Šé—¨åŒ–å¦†å¤šå°‘é’±,æˆéƒ½ä¸Šé—¨åŒ–å¦†').split(',')
SEARCH_COUNT = int(os.getenv('XHS_COUNT', '10'))  # å¢åŠ æœç´¢æ•°é‡

# å¤‡ç”¨å…³é”®è¯ï¼šå½“ä¸»è¦å…³é”®è¯æ•ˆæœä¸å¥½æ—¶ä½¿ç”¨
BACKUP_KEYWORDS = ["æ±‚æ¨èåŒ–å¦†å¸ˆ", "æ±‚ä¸€ä¸ªæ—¥å¸¸å¦†æ•™ç¨‹", "æ–°æ‰‹æ€ä¹ˆç”»çœ¼çº¿å•Š", "è¿™ä¸ªå¦†æœ‰æ²¡æœ‰å§å¦¹æ•™æˆ‘ä¸€ä¸‹"]
XHS_COOKIE = os.getenv('XHS_COOKIE', os.getenv('COOKIES', ''))  # å…¼å®¹COOKIESå˜é‡å
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '')  # DeepSeek APIå¯†é’¥

# å…¼å®¹æ—§ç‰ˆæœ¬å•ä¸ªå…³é”®è¯é…ç½® - åªåœ¨æ²¡æœ‰è®¾ç½®æ–°é…ç½®æ—¶ä½¿ç”¨
if os.getenv('XHS_KEYWORD') and not os.getenv('XHS_KEYWORDS'):
    SEARCH_KEYWORDS = [os.getenv('XHS_KEYWORD')]

# æ•°æ®å­˜å‚¨è·¯å¾„
SEEN_NOTES_FILE = os.getenv('XHS_SEEN_FILE', '/ql/data/scripts/xhs_seen_notes.json')

# å¦‚æœåœ¨éé’é¾™ç¯å¢ƒä¸­ï¼Œä½¿ç”¨å½“å‰ç›®å½•
if not os.path.exists(os.path.dirname(SEEN_NOTES_FILE)):
    SEEN_NOTES_FILE = os.path.join(current_dir, 'xhs_seen_notes.json')

class XHSMonitor:
    def __init__(self):
        self.seen_notes = self.load_seen_notes()
        self.data_spider = Data_Spider()

    def load_seen_notes(self):
        """åŠ è½½å·²çœ‹è¿‡çš„ç¬”è®°ID"""
        try:
            if os.path.exists(SEEN_NOTES_FILE):
                with open(SEEN_NOTES_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('seen_ids', []))
            return set()
        except Exception as e:
            print(f"åŠ è½½å·²çœ‹ç¬”è®°è®°å½•å¤±è´¥: {e}")
            return set()

    def save_seen_notes(self):
        """ä¿å­˜å·²çœ‹è¿‡çš„ç¬”è®°ID"""
        try:
            os.makedirs(os.path.dirname(SEEN_NOTES_FILE), exist_ok=True)

            data = {
                'seen_ids': list(self.seen_notes),
                'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_count': len(self.seen_notes)
            }

            with open(SEEN_NOTES_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"å·²ä¿å­˜ {len(self.seen_notes)} ä¸ªç¬”è®°ID")
        except Exception as e:
            print(f"ä¿å­˜è®°å½•å¤±è´¥: {e}")

    def generate_note_id(self, note_data):
        """ç”Ÿæˆç¬”è®°å”¯ä¸€ID"""
        content = f"{note_data.get('note_id', '')}{note_data.get('title', '')}"
        return hashlib.md5(content.encode()).hexdigest()



    def is_note_seen(self, note_data):
        """æ£€æŸ¥æ˜¯å¦å·²çœ‹è¿‡"""
        note_id = self.generate_note_id(note_data)
        return note_id in self.seen_notes



    def mark_note_as_seen(self, note_data):
        """æ ‡è®°ä¸ºå·²çœ‹è¿‡"""
        note_id = self.generate_note_id(note_data)
        self.seen_notes.add(note_id)



    def create_payload(self, content):
        system_prompt = """ä½ æ˜¯å°çº¢ä¹¦å†…å®¹åˆ†æä¸“å®¶ï¼Œä¸“ä¸ºåŒ–å¦†å¸ˆç­›é€‰æ½œåœ¨å®¢æˆ·ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­è¿™ä¸ªç¬”è®°æ˜¯å¦æ˜¯æ™®é€šç”¨æˆ·å‘å¸ƒçš„ã€æœ‰åŒ–å¦†æœåŠ¡æˆ–åŒ–å¦†æ•™å­¦éœ€æ±‚çš„å¸–å­ã€‚
### ç”¨æˆ·éœ€æ±‚ç¬”è®°ç‰¹å¾ (å›ç­” YES)
åªè¦æ»¡è¶³ä»¥ä¸‹ä»»ä¸€ç±»åˆ«ï¼Œéƒ½å±äºæ½œåœ¨å®¢æˆ·ï¼š
1.  **æœåŠ¡éœ€æ±‚**: æ˜ç¡®è¡¨ç¤ºéœ€è¦**æ‰¾äººåŒ–å¦†**ã€‚
    *   ä¾‹å¦‚: "æ±‚æ¨èåŒ–å¦†å¸ˆ"ã€"æˆéƒ½çº¦å¦†"ã€"æ–°å¨˜è·Ÿå¦†å¤šå°‘é’±"ã€"æ‰¾ä¸ªåŒ–å¦†å¸ˆæ‹å†™çœŸ"ã€‚
2.  **æ•™å­¦éœ€æ±‚**: æ˜ç¡®è¡¨ç¤ºæƒ³è¦**å­¦ä¹ å¦‚ä½•è‡ªå·±åŒ–å¦†**ã€‚
    *   ä¾‹å¦‚: "æ±‚ä¸€ä¸ªæ—¥å¸¸å¦†æ•™ç¨‹"ã€"æ–°æ‰‹æ€ä¹ˆç”»çœ¼çº¿å•Š"ã€"è¿™ä¸ªå¦†æœ‰æ²¡æœ‰å§å¦¹æ•™æˆ‘ä¸€ä¸‹"ã€‚

### éå®¢æˆ·ç¬”è®°ç‰¹å¾ (å›ç­” NO)
1.  **åŒ–å¦†å¸ˆ/å•†å®¶å¹¿å‘Š**: ä»»ä½•å½¢å¼çš„è‡ªæˆ‘æ¨å¹¿ã€ä½œå“å±•ç¤ºã€æœåŠ¡ä»‹ç»ã€ä»·æ ¼è¡¨ã€ç•™è”ç³»æ–¹å¼ã€æ‹›å‹Ÿå­¦å‘˜ç­‰ã€‚
    *   ä¾‹å¦‚: "ä»Šæ—¥æ–°å¨˜ä½œå“"ã€"æ‰¿æ¥å„ç±»å¦†å®¹"ã€"åŒ–å¦†æ•™å­¦ä¸€å¯¹ä¸€"ã€‚
2.  **åˆä½œéœ€æ±‚**: æ¨¡ç‰¹æˆ–æ‘„å½±å¸ˆå¯»æ‰¾äº’å…ï¼ˆæ— å¿ï¼‰åˆä½œã€‚
    *   ä¾‹å¦‚: "å¯»æ‰¾å¦†é€ å¸ˆåˆä½œ"ã€"å¯äº’å…"ã€‚
3.  **æ— æ˜ç¡®éœ€æ±‚**: ä»…åˆ†äº«è‡ªå·±çš„å¦†å®¹æˆ–äº§å“ï¼Œæ²¡æœ‰æ±‚åŠ©æ„å›¾ã€‚

### åˆ†æè¦ç‚¹
- æ ¸å¿ƒæ˜¯åˆ¤æ–­ç¬”è®°å‘å¸ƒè€…æ˜¯åœ¨**å¯»æ±‚å¸®åŠ©ï¼ˆæ— è®ºæ˜¯æœåŠ¡è¿˜æ˜¯å­¦ä¹ ï¼‰**ï¼Œè¿˜æ˜¯åœ¨**æä¾›æœåŠ¡ï¼ˆå¹¿å‘Šæˆ–åˆä½œï¼‰**ã€‚
- ä½œè€…æ˜µç§°æˆ–ç®€ä»‹ä¸­åŒ…å«"åŒ–å¦†å¸ˆ"ã€"MUA"ã€"å·¥ä½œå®¤"ç­‰å…³é”®è¯çš„ï¼Œå¤§æ¦‚ç‡æ˜¯å¹¿å‘Šï¼ˆå›ç­”NOï¼‰ã€‚

---
**ä½ çš„å›ç­”å¿…é¡»ç®€æ´ï¼Œåªè¾“å‡ºä»¥ä¸‹ä¸¤ç§ç»“æœä¹‹ä¸€ï¼š**
- **YES** (æ˜¯æ½œåœ¨å®¢æˆ·ï¼Œæ— è®ºæ˜¯æœåŠ¡è¿˜æ˜¯æ•™å­¦éœ€æ±‚)
- **NO** (éæ½œåœ¨å®¢æˆ·)"""
        return {
            "model": "deepseek-reasoner",
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": content
                }
            ],
            "temperature": 0.1,  # ä½¿ç”¨è¾ƒä½çš„æ¸©åº¦è®©è¾“å‡ºæ›´ç¨³å®šã€æ›´å…·ç¡®å®šæ€§
            "max_tokens": 10     # å¯¹äºYES/NOçš„å›ç­”ï¼Œ10ä¸ªtokenè¶³å¤Ÿäº†
        }




    def analyze_note_intent(self, note_data):
        """ä½¿ç”¨DeepSeekåˆ†æç¬”è®°æ„å›¾"""
        if not DEEPSEEK_API_KEY:
            print("DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡æ„å›¾åˆ†æ")
            return True  # å¦‚æœæ²¡æœ‰é…ç½®APIï¼Œé»˜è®¤é€šè¿‡

        try:
            title = note_data.get('title', '')
            desc = note_data.get('desc', '')
            nickname = note_data.get('nickname', '')

            # æ„å»ºåˆ†æå†…å®¹
            content = f"æ ‡é¢˜: {title}\nä½œè€…: {nickname}\nå†…å®¹: {desc}"

            # DeepSeek APIè¯·æ±‚
            headers = {
                'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
                'Content-Type': 'application/json'
            }

            data = self.create_payload(content)

            response = requests.post(
                'https://api.deepseek.com/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                answer = result['choices'][0]['message']['content'].strip().upper()

                is_user_demand = answer == 'YES'
                print(f"AIåˆ†æç»“æœ: {answer} - {'ç”¨æˆ·éœ€æ±‚' if is_user_demand else 'åŒ–å¦†å¸ˆå¹¿å‘Š'}")
                return is_user_demand
            else:
                print(f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return True  # APIå¤±è´¥æ—¶é»˜è®¤é€šè¿‡

        except Exception as e:
            print(f"DeepSeekåˆ†æå¼‚å¸¸: {e}")
            return True  # å¼‚å¸¸æ—¶é»˜è®¤é€šè¿‡

    def search_and_get_notes(self, keywords, count=5):
        """æœç´¢å¹¶è·å–ç¬”è®°è¯¦æƒ… - æ”¯æŒå¤šå…³é”®è¯"""
        all_notes = []
        all_success_keywords = []
        failed_keywords = []

        try:
            # åˆå§‹åŒ–cookie
            try:
                cookies_str, base_path = init()
            except Exception as e:
                error_msg = f"Cookieåˆå§‹åŒ–å¤±è´¥: {str(e)}"
                print(error_msg)
                QLAPI.systemNotify({"title": "ğŸ”‘ Cookieé”™è¯¯", "content": error_msg})
                return False, error_msg, []

            if not cookies_str:
                error_msg = "Cookieæœªé…ç½®æˆ–ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡XHS_COOKIE"
                print(error_msg)
                QLAPI.systemNotify({"title": "ğŸ”‘ Cookieæœªé…ç½®", "content": error_msg})
                return False, error_msg, []

            # æ¯ä¸ªå…³é”®è¯æœç´¢çš„æ•°é‡
            per_keyword_count = max(1, count // len(keywords))

            for keyword in keywords:
                keyword = keyword.strip()
                if not keyword:
                    continue

                print(f"å¼€å§‹æœç´¢å…³é”®è¯: {keyword}")

                # éšæœºåŒ–æœç´¢å‚æ•°ï¼Œé¿å…é‡å¤ç»“æœ
                sort_choices = [0, 1, 2]  # ç»¼åˆæ’åº, æœ€æ–°, æœ€å¤šç‚¹èµ
                time_choices = [0, 1, 2]  # ä¸é™, ä¸€å¤©å†…, ä¸€å‘¨å†…

                sort_type = random.choice(sort_choices)
                note_time = random.choice(time_choices)

                print(f"æœç´¢å‚æ•°: æ’åº={sort_type}, æ—¶é—´={note_time}")

                try:
                    note_data_list, success, msg = self.data_spider.spider_some_search_note(
                        query=keyword,
                        require_num=per_keyword_count,
                        cookies_str=cookies_str,
                        base_path=None,
                        save_choice='none',
                        sort_type_choice=sort_type,  # éšæœºæ’åº
                        note_type=2,                 # æ™®é€šç¬”è®°
                        note_time=note_time,         # éšæœºæ—¶é—´èŒƒå›´
                        note_range=2,                # ä¸é™
                        pos_distance=2,              # é™„è¿‘
                        geo={                        # æˆéƒ½åœ°åŒº
                            "latitude": 30.539416,
                            "longitude": 104.070491
                        }
                    )

                    if success and note_data_list:
                        print(f"å…³é”®è¯ '{keyword}' æœç´¢æˆåŠŸï¼Œè·å–åˆ° {len(note_data_list)} ä¸ªç¬”è®°")
                        all_notes.extend(note_data_list)
                        all_success_keywords.append(keyword)
                        time.sleep(2)  # å…³é”®è¯é—´éš”
                    else:
                        error_msg = f"å…³é”®è¯ '{keyword}' æœç´¢å¤±è´¥: {msg}"
                        print(error_msg)
                        failed_keywords.append(f"{keyword}({msg})")

                        # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸¥é‡çš„ç™»å½•ç›¸å…³é”™è¯¯
                        if any(err_keyword in msg.lower() for err_keyword in ['ç™»å½•', 'login', 'cookie', '401', '403', 'unauthorized', 'forbidden']):
                            print(f"æ£€æµ‹åˆ°ç™»å½•ç›¸å…³é”™è¯¯ï¼Œä½†ç»§ç»­å°è¯•å…¶ä»–å…³é”®è¯")
                            # ä¸ç«‹å³è¿”å›ï¼Œç»§ç»­å°è¯•å…¶ä»–å…³é”®è¯

                except Exception as keyword_error:
                    error_msg = f"å…³é”®è¯ '{keyword}' æœç´¢å¼‚å¸¸: {str(keyword_error)}"
                    print(error_msg)
                    failed_keywords.append(f"{keyword}(å¼‚å¸¸: {str(keyword_error)})")
                    continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªå…³é”®è¯

            # å»é‡ï¼ˆåŸºäºnote_idï¼‰
            seen_note_ids = set()
            unique_notes = []
            for note in all_notes:
                note_id = note.get('note_id', '')
                if note_id and note_id not in seen_note_ids:
                    seen_note_ids.add(note_id)
                    unique_notes.append(note)

            # æ„å»ºç»“æœæ¶ˆæ¯
            result_parts = []
            if all_success_keywords:
                result_parts.append(f"æˆåŠŸå…³é”®è¯: {', '.join(all_success_keywords)}")
            if failed_keywords:
                result_parts.append(f"å¤±è´¥å…³é”®è¯: {', '.join(failed_keywords)}")

            result_msg = "; ".join(result_parts) if result_parts else "æ— æœ‰æ•ˆå…³é”®è¯"

            if unique_notes:
                print(f"å¤šå…³é”®è¯æœç´¢å®Œæˆï¼Œå»é‡åè·å–åˆ° {len(unique_notes)} ä¸ªç¬”è®°")
                success_msg = f"{result_msg}, è·å–{len(unique_notes)}ä¸ªç¬”è®°"
                return True, success_msg, unique_notes
            elif all_success_keywords:
                # æœ‰æˆåŠŸçš„å…³é”®è¯ä½†æ²¡æœ‰è·å–åˆ°ç¬”è®°
                return True, f"{result_msg}, ä½†æœªè·å–åˆ°ç¬”è®°", []
            else:
                # æ‰€æœ‰å…³é”®è¯éƒ½å¤±è´¥äº†
                return False, f"æ‰€æœ‰å…³é”®è¯éƒ½æœç´¢å¤±è´¥: {result_msg}", []

        except Exception as e:
            print(f"æœç´¢å¼‚å¸¸: {e}")
            return False, f"æœç´¢å¼‚å¸¸: {str(e)}", []

    def format_note_message(self, note_data):
        """æ ¼å¼åŒ–ç¬”è®°é€šçŸ¥æ¶ˆæ¯"""
        title = f"ğŸ“ {note_data.get('title', 'æ— æ ‡é¢˜')[:30]}"

        content_parts = [
            f"ğŸ‘¤ ä½œè€…: {note_data.get('nickname', 'æœªçŸ¥')}",
            f"â¤ï¸ ç‚¹èµ: {note_data.get('liked_count', 0)}",
            f"ğŸ’¬ è¯„è®º: {note_data.get('comment_count', 0)}",
            f"ğŸ”¥ æ”¶è—: {note_data.get('collected_count', 0)}",
        ]

        # ç¬”è®°æè¿°å†…å®¹ï¼ˆå®Œæ•´å†…å®¹ï¼Œä¸æˆªå–ï¼‰
        if note_data.get('desc'):
            content_parts.append(f"ğŸ“„ å†…å®¹: {note_data.get('desc')}")

        # æ ‡ç­¾
        if note_data.get('tags'):
            tags = " ".join([f"#{tag}" for tag in note_data.get('tags', [])[:3]])
            content_parts.append(f"ğŸ·ï¸ æ ‡ç­¾: {tags}")

        # ç¬”è®°é“¾æ¥
        if note_data.get('note_url'):
            content_parts.append(f"ğŸ”— é“¾æ¥: {note_data.get('note_url')}")

        # å‘å¸ƒæ—¶é—´
        if note_data.get('upload_time'):
            content_parts.append(f"â° å‘å¸ƒ: {note_data.get('upload_time')}")

        # å›¾ç‰‡æ•°é‡
        if note_data.get('image_list'):
            content_parts.append(f"ğŸ–¼ï¸ å›¾ç‰‡: {len(note_data.get('image_list', []))} å¼ ")

        return title, "\n".join(content_parts)

    def run(self):
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        try:
            print(f"å¼€å§‹ç›‘æ§ï¼Œä½¿ç”¨å…³é”®è¯: {', '.join(SEARCH_KEYWORDS)}")

            # æœç´¢å¹¶è·å–ç¬”è®°è¯¦æƒ…
            success, msg, note_data_list = self.search_and_get_notes(SEARCH_KEYWORDS, SEARCH_COUNT)

            if not success:
                print(f"æœç´¢å¤±è´¥: {msg}")

                # æ£€æŸ¥æ˜¯å¦æ˜¯ç™»å½•ç›¸å…³é”™è¯¯
                if any(err_keyword in msg.lower() for err_keyword in ['ç™»å½•', 'login', 'cookie', '401', '403', 'unauthorized', 'forbidden', 'cookieæœªé…ç½®', 'cookieé”™è¯¯']):
                    QLAPI.systemNotify({
                        "title": "ğŸ”‘ ç™»å½•éªŒè¯å¤±è´¥",
                        "content": f"å°çº¢ä¹¦è´¦å·éªŒè¯å¤±è´¥\n\né”™è¯¯è¯¦æƒ…:\n{msg}\n\nè§£å†³æ–¹æ¡ˆ:\n1. æ£€æŸ¥Cookieæ˜¯å¦è¿‡æœŸ\n2. é‡æ–°è·å–XHS_COOKIE\n3. ç¡®è®¤è´¦å·çŠ¶æ€æ­£å¸¸"
                    })
                else:
                    QLAPI.systemNotify({"title": "âŒ æœç´¢å¤±è´¥", "content": f"{', '.join(SEARCH_KEYWORDS)}\n{msg}"})
                return False

            if not note_data_list:
                print("æœªæ‰¾åˆ°ç¬”è®°")
                QLAPI.systemNotify({"title": "â„¹ï¸ ç›‘æ§ç»“æœ", "content": f"{', '.join(SEARCH_KEYWORDS)}\næœªæ‰¾åˆ°ç›¸å…³ç¬”è®°"})
                return True

            print(f"è·å–åˆ° {len(note_data_list)} ä¸ªç¬”è®°")

            # è¿‡æ»¤æ–°ç¬”è®°å¹¶è¿›è¡ŒAIæ„å›¾åˆ†æ
            new_notes = []
            new_notes_count = 0  # æ–°ç¬”è®°æ€»æ•°
            filtered_ads_count = 0  # è¢«è¿‡æ»¤çš„å¹¿å‘Šæ•°

            for note_data in note_data_list:
                if not self.is_note_seen(note_data):
                    new_notes_count += 1
                    # ä½¿ç”¨DeepSeekåˆ†æç¬”è®°æ„å›¾
                    print(f"åˆ†æç¬”è®°: {note_data.get('title', '')[:30]}")
                    is_user_demand = self.analyze_note_intent(note_data)

                    if is_user_demand:
                        new_notes.append(note_data)
                        print(f"âœ… ç”¨æˆ·éœ€æ±‚ç¬”è®°ï¼ŒåŠ å…¥é€šçŸ¥é˜Ÿåˆ—")
                    else:
                        filtered_ads_count += 1
                        print(f"âŒ åŒ–å¦†å¸ˆå¹¿å‘Šç¬”è®°ï¼Œå·²è¿‡æ»¤")

                    self.mark_note_as_seen(note_data)
                    time.sleep(1)  # APIè¯·æ±‚é—´éš”
                else:
                    print(f"å·²çœ‹è¿‡: {note_data.get('title', '')[:20]}")

            # ä¿å­˜è®°å½•
            self.save_seen_notes()

            # å‘é€æ±‡æ€»é€šçŸ¥
            summary = f"""ğŸ“Š ç›‘æ§æ±‡æ€» - {', '.join(SEARCH_KEYWORDS)}
ğŸ“ è·å–ç¬”è®°: {len(note_data_list)} ä¸ª
ğŸ†• æ–°å¢ç¬”è®°: {new_notes_count} ä¸ª
ğŸ¤– AIç­›é€‰å: {len(new_notes)} ä¸ªç”¨æˆ·éœ€æ±‚
ğŸš« è¿‡æ»¤å¹¿å‘Š: {filtered_ads_count} ä¸ªåŒ–å¦†å¸ˆå¹¿å‘Š
â° æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}
ğŸ“Š å†å²è®°å½•: {len(self.seen_notes)} ä¸ª"""

            QLAPI.systemNotify({"title": "ğŸ“Š å°çº¢ä¹¦ç›‘æ§", "content": summary})

            # å¦‚æœç”¨æˆ·éœ€æ±‚ç¬”è®°å¤ªå°‘ï¼Œå°è¯•å¤‡ç”¨å…³é”®è¯
            if len(new_notes) == 0 and len(note_data_list) > 0:
                print("ä¸»è¦å…³é”®è¯æœªæ‰¾åˆ°ç”¨æˆ·éœ€æ±‚ï¼Œå°è¯•å¤‡ç”¨å…³é”®è¯...")
                backup_keyword = random.choice(BACKUP_KEYWORDS)
                print(f"ä½¿ç”¨å¤‡ç”¨å…³é”®è¯: {backup_keyword}")

                backup_success, backup_msg, backup_notes = self.search_and_get_notes([backup_keyword], 5)
                if backup_success and backup_notes:
                    for note_data in backup_notes:
                        if not self.is_note_seen(note_data):
                            print(f"å¤‡ç”¨æœç´¢åˆ†æ: {note_data.get('title', '')[:30]}")
                            is_user_demand = self.analyze_note_intent(note_data)

                            if is_user_demand:
                                new_notes.append(note_data)
                                print(f"âœ… å¤‡ç”¨æœç´¢æ‰¾åˆ°ç”¨æˆ·éœ€æ±‚ç¬”è®°")

                            self.mark_note_as_seen(note_data)
                            time.sleep(1)

                    self.save_seen_notes()

            # å‘é€æ–°ç¬”è®°é€šçŸ¥
            for i, note_data in enumerate(new_notes, 1):
                title, content = self.format_note_message(note_data)
                QLAPI.systemNotify({"title": title, "content": content})
                print(f"å·²é€šçŸ¥ç¬¬ {i} ä¸ªæ–°ç¬”è®°")
                if i < len(new_notes):
                    time.sleep(3)

            print(f"å®Œæˆ! æ–°ç¬”è®°: {len(new_notes)} ä¸ª")
            return True

        except Exception as e:
            error = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
            print(error)

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç™»å½•ç›¸å…³å¼‚å¸¸
            error_str = str(e).lower()
            if any(err_keyword in error_str for err_keyword in ['ç™»å½•', 'login', 'cookie', '401', '403', 'unauthorized', 'forbidden']):
                QLAPI.systemNotify({
                    "title": "ğŸ”‘ ç™»å½•å¼‚å¸¸",
                    "content": f"å°çº¢ä¹¦ç™»å½•éªŒè¯å¼‚å¸¸\n\nå¼‚å¸¸è¯¦æƒ…:\n{error}\n\nå¯èƒ½åŸå› :\n1. Cookieå·²è¿‡æœŸ\n2. è´¦å·è¢«é™åˆ¶\n3. ç½‘ç»œè¿æ¥é—®é¢˜\n4. APIæ¥å£å˜æ›´"
                })
            else:
                QLAPI.systemNotify({"title": "ğŸ’¥ ç›‘æ§å¼‚å¸¸", "content": error})
            return False

def main():
    monitor = XHSMonitor()
    success = monitor.run()
    if not success:
        exit(1)

if __name__ == "__main__":
    main()

