#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å°çº¢ä¹¦çˆ¬è™« - é’é¾™é¢æ¿ç‰ˆ
æœç´¢"æˆéƒ½çº¦å¦†"å…³é”®è¯ï¼Œé€šè¿‡QLAPIå‘é€é€šçŸ¥ï¼Œé¿å…é‡å¤é€šçŸ¥
æ¯10åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡

cron: 0 0,6-23 * * *
new Env('å°çº¢ä¹¦æˆéƒ½çº¦å¦†ç›‘æ§');
"""

import os
import sys
import json
import time
import hashlib
import requests
import random
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

try:
    from main import Data_Spider
    from xhs_utils.common_util import init
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# é’é¾™é¢æ¿QLAPI
try:
    from ql import QLAPI
except ImportError:
    # å¦‚æœä¸åœ¨é’é¾™ç¯å¢ƒä¸­ï¼Œä½¿ç”¨printæ¨¡æ‹Ÿ
    class MockQLAPI:
        @staticmethod
        def notify(data):
            print(f"\n=== é€šçŸ¥ ===")
            print(f"æ ‡é¢˜: {data.get('title', 'æ— æ ‡é¢˜')}")
            print(f"å†…å®¹: {data.get('content', 'æ— å†…å®¹')}")
            print("==========\n")

        @staticmethod
        def systemNotify(data):
            print(f"\n=== ç³»ç»Ÿé€šçŸ¥ ===")
            print(f"æ ‡é¢˜: {data.get('title', 'æ— æ ‡é¢˜')}")
            print(f"å†…å®¹: {data.get('content', 'æ— å†…å®¹')}")
            print("===============\n")
    QLAPI = MockQLAPI()

# é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–
# ä¼˜åŒ–å…³é”®è¯ï¼šæ›´åå‘ç”¨æˆ·éœ€æ±‚çš„è¡¨è¾¾æ–¹å¼
SEARCH_KEYWORDS = os.getenv('XHS_KEYWORDS', 'æˆéƒ½åŒ–å¦†æ¨è,æˆéƒ½å“ªé‡ŒåŒ–å¦†,æˆéƒ½åŒ–å¦†å“ªå®¶å¥½,æˆéƒ½ç¾å¦†æ¨è,æˆéƒ½åŒ–å¦†åº—æ¨è,æˆéƒ½åŒ–å¦†æ”»ç•¥').split(',')
SEARCH_COUNT = int(os.getenv('XHS_COUNT', '50'))  # å¢åŠ æœç´¢æ•°é‡

# å¤‡ç”¨å…³é”®è¯ï¼šå½“ä¸»è¦å…³é”®è¯æ•ˆæœä¸å¥½æ—¶ä½¿ç”¨
BACKUP_KEYWORDS = ['æˆéƒ½ç¾å¦†', 'æˆéƒ½åŒ–å¦†', 'æˆéƒ½å¦†å®¹', 'æˆéƒ½ç¾å®¹', 'æˆéƒ½å½©å¦†', 'æˆéƒ½é€ å‹']
XHS_COOKIE = os.getenv('XHS_COOKIE', os.getenv('COOKIES', ''))  # å…¼å®¹COOKIESå˜é‡å
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '')  # DeepSeek APIå¯†é’¥

# å…¼å®¹æ—§ç‰ˆæœ¬å•ä¸ªå…³é”®è¯é…ç½® - åªåœ¨æ²¡æœ‰è®¾ç½®æ–°é…ç½®æ—¶ä½¿ç”¨
if os.getenv('XHS_KEYWORD') and not os.getenv('XHS_KEYWORDS'):
    SEARCH_KEYWORDS = [os.getenv('XHS_KEYWORD')]

# æ•°æ®å­˜å‚¨è·¯å¾„
SEEN_NOTES_FILE = os.getenv('XHS_SEEN_FILE', '/ql/data/scripts/xhs_seen_notes.json')

# å¦‚æœåœ¨éé’é¾™ç¯å¢ƒä¸­ï¼Œä½¿ç”¨å½“å‰ç›®å½•
if not os.path.exists(os.path.dirname(SEEN_NOTES_FILE)):
    SEEN_NOTES_FILE = os.path.join(current_dir, 'xhs_seen_notes.json')

class XHSMonitor:
    def __init__(self):
        self.seen_notes = self.load_seen_notes()
        self.data_spider = Data_Spider()

    def load_seen_notes(self):
        """åŠ è½½å·²çœ‹è¿‡çš„ç¬”è®°ID"""
        try:
            if os.path.exists(SEEN_NOTES_FILE):
                with open(SEEN_NOTES_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('seen_ids', []))
            return set()
        except Exception as e:
            print(f"åŠ è½½å·²çœ‹ç¬”è®°è®°å½•å¤±è´¥: {e}")
            return set()

    def save_seen_notes(self):
        """ä¿å­˜å·²çœ‹è¿‡çš„ç¬”è®°ID"""
        try:
            os.makedirs(os.path.dirname(SEEN_NOTES_FILE), exist_ok=True)

            data = {
                'seen_ids': list(self.seen_notes),
                'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_count': len(self.seen_notes)
            }

            with open(SEEN_NOTES_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"å·²ä¿å­˜ {len(self.seen_notes)} ä¸ªç¬”è®°ID")
        except Exception as e:
            print(f"ä¿å­˜è®°å½•å¤±è´¥: {e}")

    def generate_note_id(self, note_data):
        """ç”Ÿæˆç¬”è®°å”¯ä¸€ID"""
        content = f"{note_data.get('note_id', '')}{note_data.get('title', '')}"
        return hashlib.md5(content.encode()).hexdigest()

    def is_note_seen(self, note_data):
        """æ£€æŸ¥æ˜¯å¦å·²çœ‹è¿‡"""
        note_id = self.generate_note_id(note_data)
        return note_id in self.seen_notes

    def mark_note_as_seen(self, note_data):
        """æ ‡è®°ä¸ºå·²çœ‹è¿‡"""
        note_id = self.generate_note_id(note_data)
        self.seen_notes.add(note_id)

    def analyze_note_intent(self, note_data):
        """ä½¿ç”¨DeepSeekåˆ†æç¬”è®°æ„å›¾"""
        if not DEEPSEEK_API_KEY:
            print("DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡æ„å›¾åˆ†æ")
            return True  # å¦‚æœæ²¡æœ‰é…ç½®APIï¼Œé»˜è®¤é€šè¿‡

        try:
            title = note_data.get('title', '')
            desc = note_data.get('desc', '')
            nickname = note_data.get('nickname', '')

            # æ„å»ºåˆ†æå†…å®¹
            content = f"æ ‡é¢˜: {title}\nä½œè€…: {nickname}\nå†…å®¹: {desc}"

            # DeepSeek APIè¯·æ±‚
            headers = {
                'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
                'Content-Type': 'application/json'
            }

            data = {
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯å°çº¢ä¹¦å†…å®¹åˆ†æä¸“å®¶ã€‚è¯·åˆ¤æ–­è¿™ä¸ªç¬”è®°æ˜¯å¦æ˜¯æ™®é€šç”¨æˆ·å‘å¸ƒçš„æœ‰åŒ–å¦†éœ€æ±‚çš„å†…å®¹ã€‚

ç”¨æˆ·éœ€æ±‚ç¬”è®°ç‰¹å¾ï¼ˆå›ç­”YESï¼‰ï¼š
1. æ±‚åŠ©ç±»ï¼šæ±‚æ¨èã€æ±‚æ”»ç•¥ã€é—®å“ªé‡Œå¥½ã€å’¨è¯¢ä»·æ ¼
2. åˆ†äº«ç±»ï¼šä½œä¸ºé¡¾å®¢åˆ†äº«ä½“éªŒã€æ™’åŒ–å¦†æ•ˆæœã€è®°å½•è¿‡ç¨‹
3. ç–‘é—®ç±»ï¼šè¯¢é—®åŒ–å¦†ç›¸å…³é—®é¢˜ã€å¯¹æ¯”é€‰æ‹©ã€æ±‚å»ºè®®
4. è¯­æ°”ï¼šä½¿ç”¨"å§å¦¹ä»¬"ã€"å®å­ä»¬"ã€"æ±‚æ¨è"ã€"æœ‰æ²¡æœ‰"ã€"æ€ä¹ˆæ ·"

åŒ–å¦†å¸ˆå¹¿å‘Šç‰¹å¾ï¼ˆå›ç­”NOï¼‰ï¼š
1. æœåŠ¡å®£ä¼ ï¼šæ¥å•ã€çº¦å¦†ã€å¯é¢„çº¦ã€è”ç³»æˆ‘ã€ä»·æ ¼é€æ˜
2. æŠ€æœ¯å±•ç¤ºï¼šä¸“ä¸šåŒ–å¦†å¸ˆã€å·¥ä½œå®¤ã€ä½œå“å±•ç¤ºã€å®¢æˆ·æ¡ˆä¾‹
3. è¥é”€è¯­è¨€ï¼šé€Ÿçº¦ã€ä¸€å¯¹ä¸€ã€ä¸Šé—¨æœåŠ¡ã€æ¡£æœŸã€æ’æœŸ
4. æ˜µç§°ç‰¹å¾ï¼šåŒ…å«"åŒ–å¦†å¸ˆ"ã€"ç¾å¦†"ã€"å·¥ä½œå®¤"ç­‰

åˆ†æè¦ç‚¹ï¼š
- é‡ç‚¹çœ‹å†…å®¹è¯­æ°”å’Œè¡¨è¾¾æ–¹å¼
- æ™®é€šç”¨æˆ·å¤šç”¨ç–‘é—®å¥å’Œæ±‚åŠ©è¯­æ°”
- åŒ–å¦†å¸ˆå¤šç”¨è‚¯å®šå¥å’Œæ¨é”€è¯­è¨€

åªå›ç­”ï¼šYESï¼ˆç”¨æˆ·éœ€æ±‚ï¼‰æˆ– NOï¼ˆåŒ–å¦†å¸ˆå¹¿å‘Šï¼‰"""
                    },
                    {
                        "role": "user",
                        "content": content
                    }
                ],
                "temperature": 0.1,
                "max_tokens": 10
            }

            response = requests.post(
                'https://api.deepseek.com/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                answer = result['choices'][0]['message']['content'].strip().upper()

                is_user_demand = answer == 'YES'
                print(f"AIåˆ†æç»“æœ: {answer} - {'ç”¨æˆ·éœ€æ±‚' if is_user_demand else 'åŒ–å¦†å¸ˆå¹¿å‘Š'}")
                return is_user_demand
            else:
                print(f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return True  # APIå¤±è´¥æ—¶é»˜è®¤é€šè¿‡

        except Exception as e:
            print(f"DeepSeekåˆ†æå¼‚å¸¸: {e}")
            return True  # å¼‚å¸¸æ—¶é»˜è®¤é€šè¿‡

    def search_and_get_notes(self, keywords, count=5):
        """æœç´¢å¹¶è·å–ç¬”è®°è¯¦æƒ… - æ”¯æŒå¤šå…³é”®è¯"""
        all_notes = []
        all_success_keywords = []

        try:
            # åˆå§‹åŒ–cookie
            cookies_str, base_path = init()
            if not cookies_str:
                return False, "Cookieæœªé…ç½®", []

            # æ¯ä¸ªå…³é”®è¯æœç´¢çš„æ•°é‡
            per_keyword_count = max(1, count // len(keywords))

            for keyword in keywords:
                keyword = keyword.strip()
                if not keyword:
                    continue

                print(f"å¼€å§‹æœç´¢å…³é”®è¯: {keyword}")

                # éšæœºåŒ–æœç´¢å‚æ•°ï¼Œé¿å…é‡å¤ç»“æœ
                sort_choices = [0, 1, 2]  # ç»¼åˆæ’åº, æœ€æ–°, æœ€å¤šç‚¹èµ
                time_choices = [0, 1, 2]  # ä¸é™, ä¸€å¤©å†…, ä¸€å‘¨å†…

                sort_type = random.choice(sort_choices)
                note_time = random.choice(time_choices)

                print(f"æœç´¢å‚æ•°: æ’åº={sort_type}, æ—¶é—´={note_time}")

                note_data_list, success, msg = self.data_spider.spider_some_search_note(
                    query=keyword,
                    require_num=per_keyword_count,
                    cookies_str=cookies_str,
                    base_path=None,
                    save_choice='none',
                    sort_type_choice=sort_type,  # éšæœºæ’åº
                    note_type=2,                 # æ™®é€šç¬”è®°
                    note_time=note_time,         # éšæœºæ—¶é—´èŒƒå›´
                    note_range=0,                # ä¸é™
                    pos_distance=2,              # é™„è¿‘
                    geo={                        # æˆéƒ½åœ°åŒº
                        "latitude": 30.539416,
                        "longitude": 104.070491
                    }
                )

                if success and note_data_list:
                    print(f"å…³é”®è¯ '{keyword}' æœç´¢æˆåŠŸï¼Œè·å–åˆ° {len(note_data_list)} ä¸ªç¬”è®°")
                    all_notes.extend(note_data_list)
                    all_success_keywords.append(keyword)
                    time.sleep(2)  # å…³é”®è¯é—´éš”
                else:
                    print(f"å…³é”®è¯ '{keyword}' æœç´¢å¤±è´¥: {msg}")

            # å»é‡ï¼ˆåŸºäºnote_idï¼‰
            seen_note_ids = set()
            unique_notes = []
            for note in all_notes:
                note_id = note.get('note_id', '')
                if note_id and note_id not in seen_note_ids:
                    seen_note_ids.add(note_id)
                    unique_notes.append(note)

            if unique_notes:
                print(f"å¤šå…³é”®è¯æœç´¢å®Œæˆï¼Œå»é‡åè·å–åˆ° {len(unique_notes)} ä¸ªç¬”è®°")
                success_msg = f"æˆåŠŸå…³é”®è¯: {', '.join(all_success_keywords)}, è·å–{len(unique_notes)}ä¸ªç¬”è®°"
                return True, success_msg, unique_notes
            else:
                return False, "æ‰€æœ‰å…³é”®è¯éƒ½æœªæ‰¾åˆ°ç›¸å…³ç¬”è®°", []

        except Exception as e:
            print(f"æœç´¢å¼‚å¸¸: {e}")
            return False, f"æœç´¢å¼‚å¸¸: {str(e)}", []

    def format_note_message(self, note_data):
        """æ ¼å¼åŒ–ç¬”è®°é€šçŸ¥æ¶ˆæ¯"""
        title = f"ğŸ“ {note_data.get('title', 'æ— æ ‡é¢˜')[:30]}"

        content_parts = [
            f"ğŸ‘¤ ä½œè€…: {note_data.get('nickname', 'æœªçŸ¥')}",
            f"â¤ï¸ ç‚¹èµ: {note_data.get('liked_count', 0)}",
            f"ğŸ’¬ è¯„è®º: {note_data.get('comment_count', 0)}",
            f"ğŸ”¥ æ”¶è—: {note_data.get('collected_count', 0)}",
        ]

        # ç¬”è®°æè¿°å†…å®¹ï¼ˆå®Œæ•´å†…å®¹ï¼Œä¸æˆªå–ï¼‰
        if note_data.get('desc'):
            content_parts.append(f"ğŸ“„ å†…å®¹: {note_data.get('desc')}")

        # æ ‡ç­¾
        if note_data.get('tags'):
            tags = " ".join([f"#{tag}" for tag in note_data.get('tags', [])[:3]])
            content_parts.append(f"ğŸ·ï¸ æ ‡ç­¾: {tags}")

        # ç¬”è®°é“¾æ¥
        if note_data.get('note_url'):
            content_parts.append(f"ğŸ”— é“¾æ¥: {note_data.get('note_url')}")

        # å‘å¸ƒæ—¶é—´
        if note_data.get('upload_time'):
            content_parts.append(f"â° å‘å¸ƒ: {note_data.get('upload_time')}")

        # å›¾ç‰‡æ•°é‡
        if note_data.get('image_list'):
            content_parts.append(f"ğŸ–¼ï¸ å›¾ç‰‡: {len(note_data.get('image_list', []))} å¼ ")

        return title, "\n".join(content_parts)

    def run(self):
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        try:
            print(f"å¼€å§‹ç›‘æ§ï¼Œä½¿ç”¨å…³é”®è¯: {', '.join(SEARCH_KEYWORDS)}")

            # æœç´¢å¹¶è·å–ç¬”è®°è¯¦æƒ…
            success, msg, note_data_list = self.search_and_get_notes(SEARCH_KEYWORDS, SEARCH_COUNT)

            if not success:
                print(f"æœç´¢å¤±è´¥: {msg}")
                QLAPI.systemNotify({"title": "âŒ æœç´¢å¤±è´¥", "content": f"{', '.join(SEARCH_KEYWORDS)}\n{msg}"})
                return False

            if not note_data_list:
                print("æœªæ‰¾åˆ°ç¬”è®°")
                QLAPI.systemNotify({"title": "â„¹ï¸ ç›‘æ§ç»“æœ", "content": f"{', '.join(SEARCH_KEYWORDS)}\næœªæ‰¾åˆ°ç›¸å…³ç¬”è®°"})
                return True

            print(f"è·å–åˆ° {len(note_data_list)} ä¸ªç¬”è®°")

            # è¿‡æ»¤æ–°ç¬”è®°å¹¶è¿›è¡ŒAIæ„å›¾åˆ†æ
            new_notes = []
            new_notes_count = 0  # æ–°ç¬”è®°æ€»æ•°
            filtered_ads_count = 0  # è¢«è¿‡æ»¤çš„å¹¿å‘Šæ•°

            for note_data in note_data_list:
                if not self.is_note_seen(note_data):
                    new_notes_count += 1
                    # ä½¿ç”¨DeepSeekåˆ†æç¬”è®°æ„å›¾
                    print(f"åˆ†æç¬”è®°: {note_data.get('title', '')[:30]}")
                    is_user_demand = self.analyze_note_intent(note_data)

                    if is_user_demand:
                        new_notes.append(note_data)
                        print(f"âœ… ç”¨æˆ·éœ€æ±‚ç¬”è®°ï¼ŒåŠ å…¥é€šçŸ¥é˜Ÿåˆ—")
                    else:
                        filtered_ads_count += 1
                        print(f"âŒ åŒ–å¦†å¸ˆå¹¿å‘Šç¬”è®°ï¼Œå·²è¿‡æ»¤")

                    self.mark_note_as_seen(note_data)
                    time.sleep(1)  # APIè¯·æ±‚é—´éš”
                else:
                    print(f"å·²çœ‹è¿‡: {note_data.get('title', '')[:20]}")

            # ä¿å­˜è®°å½•
            self.save_seen_notes()

            # å‘é€æ±‡æ€»é€šçŸ¥
            summary = f"""ğŸ“Š ç›‘æ§æ±‡æ€» - {', '.join(SEARCH_KEYWORDS)}
ğŸ“ è·å–ç¬”è®°: {len(note_data_list)} ä¸ª
ğŸ†• æ–°å¢ç¬”è®°: {new_notes_count} ä¸ª
ğŸ¤– AIç­›é€‰å: {len(new_notes)} ä¸ªç”¨æˆ·éœ€æ±‚
ğŸš« è¿‡æ»¤å¹¿å‘Š: {filtered_ads_count} ä¸ªåŒ–å¦†å¸ˆå¹¿å‘Š
â° æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}
ğŸ“Š å†å²è®°å½•: {len(self.seen_notes)} ä¸ª"""

            QLAPI.systemNotify({"title": "ğŸ“Š å°çº¢ä¹¦ç›‘æ§", "content": summary})

            # å¦‚æœç”¨æˆ·éœ€æ±‚ç¬”è®°å¤ªå°‘ï¼Œå°è¯•å¤‡ç”¨å…³é”®è¯
            if len(new_notes) == 0 and len(note_data_list) > 0:
                print("ä¸»è¦å…³é”®è¯æœªæ‰¾åˆ°ç”¨æˆ·éœ€æ±‚ï¼Œå°è¯•å¤‡ç”¨å…³é”®è¯...")
                backup_keyword = random.choice(BACKUP_KEYWORDS)
                print(f"ä½¿ç”¨å¤‡ç”¨å…³é”®è¯: {backup_keyword}")

                backup_success, backup_msg, backup_notes = self.search_and_get_notes([backup_keyword], 5)
                if backup_success and backup_notes:
                    for note_data in backup_notes:
                        if not self.is_note_seen(note_data):
                            print(f"å¤‡ç”¨æœç´¢åˆ†æ: {note_data.get('title', '')[:30]}")
                            is_user_demand = self.analyze_note_intent(note_data)

                            if is_user_demand:
                                new_notes.append(note_data)
                                print(f"âœ… å¤‡ç”¨æœç´¢æ‰¾åˆ°ç”¨æˆ·éœ€æ±‚ç¬”è®°")

                            self.mark_note_as_seen(note_data)
                            time.sleep(1)

                    self.save_seen_notes()

            # å‘é€æ–°ç¬”è®°é€šçŸ¥
            for i, note_data in enumerate(new_notes, 1):
                title, content = self.format_note_message(note_data)
                QLAPI.systemNotify({"title": title, "content": content})
                print(f"å·²é€šçŸ¥ç¬¬ {i} ä¸ªæ–°ç¬”è®°")
                if i < len(new_notes):
                    time.sleep(3)

            print(f"å®Œæˆ! æ–°ç¬”è®°: {len(new_notes)} ä¸ª")
            return True

        except Exception as e:
            error = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
            print(error)
            QLAPI.systemNotify({"title": "ğŸ’¥ ç›‘æ§å¼‚å¸¸", "content": error})
            return False

def main():
    monitor = XHSMonitor()
    success = monitor.run()
    if not success:
        exit(1)

if __name__ == "__main__":
    main()
