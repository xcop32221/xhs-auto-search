#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å°çº¢ä¹¦çˆ¬è™« - é’é¾™é¢æ¿ç‰ˆ
æœç´¢"æˆéƒ½çº¦å¦†"å…³é”®è¯ï¼Œé€šè¿‡QLAPIå‘é€é€šçŸ¥ï¼Œé¿å…é‡å¤é€šçŸ¥
æ¯10åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡

cron: */10 * * * *
new Env('å°çº¢ä¹¦æˆéƒ½çº¦å¦†ç›‘æ§');
"""

import os
import sys
import json
import time
import hashlib
import requests
from datetime import datetime

# é’é¾™é¢æ¿QLAPI
try:
    from ql import QLAPI
except ImportError:
    # å¦‚æœä¸åœ¨é’é¾™ç¯å¢ƒä¸­ï¼Œä½¿ç”¨printæ¨¡æ‹Ÿ
    class MockQLAPI:
        @staticmethod
        def notify(title, content):
            print(f"\n=== é€šçŸ¥ ===")
            print(f"æ ‡é¢˜: {title}")
            print(f"å†…å®¹: {content}")
            print("==========\n")
    QLAPI = MockQLAPI()

# é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–
SEARCH_KEYWORD = os.getenv('XHS_KEYWORD', 'æˆéƒ½çº¦å¦†')
SEARCH_COUNT = int(os.getenv('XHS_COUNT', '5'))
XHS_COOKIE = os.getenv('XHS_COOKIE', os.getenv('COOKIES', ''))  # å…¼å®¹COOKIESå˜é‡å

# æ•°æ®å­˜å‚¨è·¯å¾„
SEEN_NOTES_FILE = "/ql/data/scripts/xhs_seen_notes.json"

class XHSMonitor:
    def __init__(self):
        self.seen_notes = self.load_seen_notes()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Cookie': XHS_COOKIE,
            'Referer': 'https://www.xiaohongshu.com/',
            'Origin': 'https://www.xiaohongshu.com'
        })

    def load_seen_notes(self):
        """åŠ è½½å·²çœ‹è¿‡çš„ç¬”è®°ID"""
        try:
            if os.path.exists(SEEN_NOTES_FILE):
                with open(SEEN_NOTES_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return set(data.get('seen_ids', []))
            return set()
        except Exception as e:
            print(f"åŠ è½½å·²çœ‹ç¬”è®°è®°å½•å¤±è´¥: {e}")
            return set()

    def save_seen_notes(self):
        """ä¿å­˜å·²çœ‹è¿‡çš„ç¬”è®°ID"""
        try:
            os.makedirs(os.path.dirname(SEEN_NOTES_FILE), exist_ok=True)

            data = {
                'seen_ids': list(self.seen_notes),
                'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_count': len(self.seen_notes)
            }

            with open(SEEN_NOTES_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"å·²ä¿å­˜ {len(self.seen_notes)} ä¸ªç¬”è®°ID")
        except Exception as e:
            print(f"ä¿å­˜è®°å½•å¤±è´¥: {e}")

    def generate_note_id(self, note_data):
        """ç”Ÿæˆç¬”è®°å”¯ä¸€ID"""
        content = f"{note_data.get('id', '')}{note_data.get('title', '')}"
        return hashlib.md5(content.encode()).hexdigest()

    def is_note_seen(self, note_data):
        """æ£€æŸ¥æ˜¯å¦å·²çœ‹è¿‡"""
        note_id = self.generate_note_id(note_data)
        return note_id in self.seen_notes

    def mark_note_as_seen(self, note_data):
        """æ ‡è®°ä¸ºå·²çœ‹è¿‡"""
        note_id = self.generate_note_id(note_data)
        self.seen_notes.add(note_id)

    def search_notes(self, keyword, count=5):
        """æœç´¢ç¬”è®°"""
        try:
            url = "https://edith.xiaohongshu.com/api/sns/web/v1/search/notes"
            data = {
                "keyword": keyword,
                "page": 1,
                "page_size": count,
                "search_id": "",
                "sort": "general",
                "note_type": 0,
                "ext_flags": [],
                "image_formats": ["jpg", "webp", "avif"]
            }

            response = self.session.post(url, json=data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                if result.get('success') and result.get('data'):
                    items = result['data'].get('items', [])
                    notes = [item for item in items if item.get('model_type') == 'note']
                    return True, f"æˆåŠŸè·å–{len(notes)}ä¸ªç¬”è®°", notes
                else:
                    return False, f"APIé”™è¯¯: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}", []
            else:
                return False, f"HTTPé”™è¯¯: {response.status_code}", []

        except Exception as e:
            return False, f"æœç´¢å¼‚å¸¸: {str(e)}", []

    def get_note_detail(self, note_id, xsec_token):
        """è·å–ç¬”è®°è¯¦æƒ…"""
        try:
            url = "https://edith.xiaohongshu.com/api/sns/web/v1/feed"
            data = {
                "source_note_id": note_id,
                "image_formats": ["jpg", "webp", "avif"],
                "extra": {"need_body_topic": "1"},
                "xsec_source": "pc_search",
                "xsec_token": xsec_token
            }

            response = self.session.post(url, json=data, timeout=30)

            if response.status_code == 200:
                result = response.json()
                if result.get('success') and result.get('data'):
                    items = result['data'].get('items', [])
                    if items:
                        return True, "æˆåŠŸ", self.parse_note_info(items[0])
                return False, "æ•°æ®ä¸ºç©º", {}
            else:
                return False, f"HTTPé”™è¯¯: {response.status_code}", {}

        except Exception as e:
            return False, f"è·å–è¯¦æƒ…å¼‚å¸¸: {str(e)}", {}

    def parse_note_info(self, note_info):
        """è§£æç¬”è®°ä¿¡æ¯"""
        try:
            note_card = note_info.get('note_card', {})
            interact_info = note_card.get('interact_info', {})
            user = note_card.get('user', {})

            return {
                'id': note_info.get('id', ''),
                'title': note_card.get('display_title', 'æ— æ ‡é¢˜'),
                'content': note_card.get('desc', ''),
                'author': user.get('nickname', 'æœªçŸ¥'),
                'likes': interact_info.get('liked_count', '0'),
                'comments': interact_info.get('comment_count', '0'),
                'views': interact_info.get('view_count', '0'),
                'publish_time': note_card.get('time', ''),
                'tags': [tag.get('name', '') for tag in note_card.get('tag_list', [])],
                'images': len(note_card.get('image_list', [])),
                'video': bool(note_card.get('video', {}).get('consumer', {}).get('origin_video_key', '')),
                'url': f"https://www.xiaohongshu.com/explore/{note_info.get('id', '')}"
            }
        except Exception as e:
            print(f"è§£æç¬”è®°ä¿¡æ¯é”™è¯¯: {e}")
            return {}

    def format_note_message(self, note_data):
        """æ ¼å¼åŒ–ç¬”è®°é€šçŸ¥æ¶ˆæ¯"""
        title = f"ğŸ“ {note_data.get('title', 'æ— æ ‡é¢˜')[:30]}"

        content_parts = [
            f"ğŸ‘¤ ä½œè€…: {note_data.get('author', 'æœªçŸ¥')}",
            f"â¤ï¸ ç‚¹èµ: {note_data.get('likes', 0)}",
            f"ğŸ’¬ è¯„è®º: {note_data.get('comments', 0)}",
        ]

        if note_data.get('content'):
            preview = note_data.get('content')[:100]
            if len(note_data.get('content')) > 100:
                preview += "..."
            content_parts.append(f"ğŸ“„ {preview}")

        if note_data.get('tags'):
            tags = " ".join([f"#{tag}" for tag in note_data.get('tags', [])[:3]])
            content_parts.append(f"ğŸ·ï¸ {tags}")

        if note_data.get('url'):
            content_parts.append(f"ğŸ”— {note_data.get('url')}")

        return title, "\n".join(content_parts)

    def run(self):
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        try:
            print(f"å¼€å§‹ç›‘æ§: {SEARCH_KEYWORD}")

            if not XHS_COOKIE:
                error = "Cookieæœªé…ç½®ï¼Œè¯·è®¾ç½®XHS_COOKIEç¯å¢ƒå˜é‡"
                print(error)
                QLAPI.notify("âŒ é…ç½®é”™è¯¯", error)
                return False

            # æœç´¢ç¬”è®°
            success, msg, notes = self.search_notes(SEARCH_KEYWORD, SEARCH_COUNT)

            if not success:
                print(f"æœç´¢å¤±è´¥: {msg}")
                QLAPI.notify("âŒ æœç´¢å¤±è´¥", f"{SEARCH_KEYWORD}\n{msg}")
                return False

            if not notes:
                print("æœªæ‰¾åˆ°ç¬”è®°")
                return True

            print(f"è·å–åˆ° {len(notes)} ä¸ªç¬”è®°")

            # è·å–è¯¦æƒ…å¹¶è¿‡æ»¤æ–°ç¬”è®°
            new_notes = []
            for note in notes:
                note_id = note.get('id', '')
                xsec_token = note.get('xsec_token', '')

                if note_id and xsec_token:
                    success, msg, note_detail = self.get_note_detail(note_id, xsec_token)
                    if success and note_detail:
                        if not self.is_note_seen(note_detail):
                            new_notes.append(note_detail)
                            self.mark_note_as_seen(note_detail)
                        else:
                            print(f"å·²çœ‹è¿‡: {note_detail.get('title', '')[:20]}")
                    time.sleep(2)  # é¿å…è¯·æ±‚è¿‡é¢‘

            # ä¿å­˜è®°å½•
            self.save_seen_notes()

            # å‘é€é€šçŸ¥
            summary = f"""ğŸ“Š ç›‘æ§æ±‡æ€» - {SEARCH_KEYWORD}
ğŸ“ è·å–: {len(notes)} ä¸ª
ğŸ†• æ–°å¢: {len(new_notes)} ä¸ª
â° {datetime.now().strftime('%H:%M:%S')}
ğŸ“Š å†å²: {len(self.seen_notes)} ä¸ª"""

            QLAPI.notify("ğŸ“Š å°çº¢ä¹¦ç›‘æ§", summary)

            # å‘é€æ–°ç¬”è®°é€šçŸ¥
            for i, note_data in enumerate(new_notes, 1):
                title, content = self.format_note_message(note_data)
                QLAPI.notify(title, content)
                print(f"å·²é€šçŸ¥ç¬¬ {i} ä¸ªæ–°ç¬”è®°")
                if i < len(new_notes):
                    time.sleep(3)

            print(f"å®Œæˆ! æ–°ç¬”è®°: {len(new_notes)} ä¸ª")
            return True

        except Exception as e:
            error = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
            print(error)
            QLAPI.notify("ğŸ’¥ ç›‘æ§å¼‚å¸¸", error)
            return False

def main():
    monitor = XHSMonitor()
    success = monitor.run()
    if not success:
        exit(1)

if __name__ == "__main__":
    main()
